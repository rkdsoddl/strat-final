{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a30c618f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7167048b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë©”ì¸ í˜ì´ì§€ ì ‘ì†(https://m.my.kt.com/product/s_OttSubscribeView.do)\n"
     ]
    }
   ],
   "source": [
    "main_url = \"https://m.my.kt.com/product/s_OttSubscribeView.do\"\n",
    "    \n",
    "headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\",\n",
    "        \"Referer\": \"https://m.my.kt.com/\"\n",
    "    }\n",
    "print(f\"ë©”ì¸ í˜ì´ì§€ ì ‘ì†({main_url})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d72d274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ì´ 0ê°œì˜ êµ¬ë… ìƒí’ˆ\n"
     ]
    }
   ],
   "source": [
    "response = requests.get(main_url, headers=headers)\n",
    "response.raise_for_status()\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "products = []\n",
    "        \n",
    "product_list = soup.select(\"ul.opage-subscription li[data-wdiclinkmobileurl]\")\n",
    "        \n",
    "print(f\" ì´ {len(product_list)}ê°œì˜ êµ¬ë… ìƒí’ˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fffbf4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\lg\\anaconda3\\envs\\test-rag\\lib\\site-packages (4.39.0)\n",
      "Requirement already satisfied: webdriver-manager in c:\\users\\lg\\anaconda3\\envs\\test-rag\\lib\\site-packages (4.0.2)\n",
      "Requirement already satisfied: urllib3<3.0,>=2.5.0 in c:\\users\\lg\\anaconda3\\envs\\test-rag\\lib\\site-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (2.6.2)\n",
      "Requirement already satisfied: trio<1.0,>=0.31.0 in c:\\users\\lg\\anaconda3\\envs\\test-rag\\lib\\site-packages (from selenium) (0.32.0)\n",
      "Requirement already satisfied: trio-websocket<1.0,>=0.12.2 in c:\\users\\lg\\anaconda3\\envs\\test-rag\\lib\\site-packages (from selenium) (0.12.2)\n",
      "Requirement already satisfied: certifi>=2025.10.5 in c:\\users\\lg\\anaconda3\\envs\\test-rag\\lib\\site-packages (from selenium) (2025.11.12)\n",
      "Requirement already satisfied: typing_extensions<5.0,>=4.15.0 in c:\\users\\lg\\anaconda3\\envs\\test-rag\\lib\\site-packages (from selenium) (4.15.0)\n",
      "Requirement already satisfied: websocket-client<2.0,>=1.8.0 in c:\\users\\lg\\anaconda3\\envs\\test-rag\\lib\\site-packages (from selenium) (1.9.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\lg\\anaconda3\\envs\\test-rag\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (25.4.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\lg\\anaconda3\\envs\\test-rag\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\lg\\anaconda3\\envs\\test-rag\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (3.11)\n",
      "Requirement already satisfied: outcome in c:\\users\\lg\\anaconda3\\envs\\test-rag\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\lg\\anaconda3\\envs\\test-rag\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\lg\\anaconda3\\envs\\test-rag\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (2.0.0)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\lg\\anaconda3\\envs\\test-rag\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (1.3.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\lg\\anaconda3\\envs\\test-rag\\lib\\site-packages (from trio-websocket<1.0,>=0.12.2->selenium) (1.3.2)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\lg\\anaconda3\\envs\\test-rag\\lib\\site-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (1.7.1)\n",
      "Requirement already satisfied: requests in c:\\users\\lg\\anaconda3\\envs\\test-rag\\lib\\site-packages (from webdriver-manager) (2.32.5)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\lg\\anaconda3\\envs\\test-rag\\lib\\site-packages (from webdriver-manager) (1.2.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\lg\\anaconda3\\envs\\test-rag\\lib\\site-packages (from webdriver-manager) (25.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\lg\\anaconda3\\envs\\test-rag\\lib\\site-packages (from cffi>=1.14->trio<1.0,>=0.31.0->selenium) (2.23)\n",
      "Requirement already satisfied: h11<1,>=0.16.0 in c:\\users\\lg\\anaconda3\\envs\\test-rag\\lib\\site-packages (from wsproto>=0.14->trio-websocket<1.0,>=0.12.2->selenium) (0.16.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\lg\\anaconda3\\envs\\test-rag\\lib\\site-packages (from requests->webdriver-manager) (3.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install selenium webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76969234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê°€ìƒ ë¸Œë¼ìš°ì €ë¥¼ ì‹¤í–‰\n",
      "í˜ì´ì§€ ì ‘ì† (https://m.my.kt.com/product/s_OttSubscribeView.do)\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import random\n",
    "\n",
    "# 1. Selenium ë¸Œë¼ìš°ì € ì„¤ì •\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # í™”ë©´ì— ì°½ì„ ë„ìš°ì§€ ì•Šê³  ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "# ì°¨ë‹¨ ë°©ì§€ë¥¼ ìœ„í•œ User-Agent ì„¤ì •\n",
    "chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\")\n",
    "\n",
    "# 2. ë¸Œë¼ìš°ì € ì‹¤í–‰\n",
    "print(\"ê°€ìƒ ë¸Œë¼ìš°ì €ë¥¼ ì‹¤í–‰\")\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "\n",
    "try:\n",
    "    # 3. ë©”ì¸ í˜ì´ì§€ ì ‘ì†\n",
    "    main_url = \"https://m.my.kt.com/product/s_OttSubscribeView.do\"\n",
    "    print(f\"í˜ì´ì§€ ì ‘ì† ({main_url})\")\n",
    "    driver.get(main_url)\n",
    "\n",
    "    #ìë°”ìŠ¤í¬ë¦½íŠ¸ê°€ ëª©ë¡ì„ ë¶ˆëŸ¬ì˜¬ ë•Œê¹Œì§€ ê¸°ë‹¤ë¦¬ê¸°\n",
    "    print(\"ë°ì´í„° ë¡œë”© ëŒ€ê¸°\")\n",
    "    time.sleep(5)\n",
    "\n",
    "    # 4. ë¡œë”©ëœ í˜ì´ì§€ì˜ HTML ê°€ì ¸ì˜¤ê¸° (ì´ì œ ë°ì´í„°ê°€ ë“¤ì–´ìˆìŒ!)\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    # 5. ëª©ë¡ ì°¾ê¸° KT í˜ì´ì§€ êµ¬ì¡°ìƒ data-wdiclinkmobileurl ì†ì„±ì´ ìˆëŠ” ë¦¬ìŠ¤íŠ¸ë¥¼ ì°¾ê¸°\n",
    "    product_list = soup.select(\"ul.opage-subscription li[data-wdiclinkmobileurl]\")\n",
    "\n",
    "    print(f\"ì´ {len(product_list)}ê°œì˜ êµ¬ë… ìƒí’ˆì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤!\")\n",
    "\n",
    "    # 6. ê²°ê³¼ ì¶œë ¥ ë° ë°ì´í„° ì¶”ì¶œ í…ŒìŠ¤íŠ¸\n",
    "    products = []\n",
    "    for li in product_list:\n",
    "        name = li.get('data-ottprodnm')\n",
    "        detail_url = li.get('data-wdiclinkmobileurl')\n",
    "        print(f\"   - ìƒí’ˆëª…: {name}\")\n",
    "        # print(f\"   - ë§í¬: {detail_url}\") \n",
    "        \n",
    "        products.append({\n",
    "            \"name\": name,\n",
    "            \"detail_url\": detail_url\n",
    "        })\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\" ì—ëŸ¬ ë°œìƒ: {e}\")\n",
    "\n",
    "finally:\n",
    "    # ë¸Œë¼ìš°ì € ì¢…ë£Œ (ë©”ëª¨ë¦¬ í™•ë³´)\n",
    "    driver.quit()\n",
    "    print(\" ë¸Œë¼ìš°ì € ì¢…ë£Œ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7f9bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ ë©”ì¸ í˜ì´ì§€ ì ‘ì† ë° ë¡œë”© ëŒ€ê¸°... (https://m.my.kt.com/product/s_OttSubscribeView.do)\n",
      "ğŸ“¦ ì´ 33ê°œì˜ ìƒí’ˆ ë°œê²¬! ìƒì„¸ ìˆ˜ì§‘ ì‹œì‘...\n",
      "   [1] ë””ì¦ˆë‹ˆí”ŒëŸ¬ìŠ¤ í”„ë¦¬ë¯¸ì—„+ë©”ê°€MGCì»¤í”¼ ì™„ë£Œ (ê°€ê²©: ì›” 13,900ì›)\n",
      "   [2] ë””ì¦ˆë‹ˆí”ŒëŸ¬ìŠ¤ ìŠ¤íƒ ë‹¤ë“œ+ë©”ê°€MGCì»¤í”¼ ì™„ë£Œ (ê°€ê²©: ì›” 9,900ì›)\n",
      "   [3] ë””ì¦ˆë‹ˆ+ í”„ë¦¬ë¯¸ì—„ ìƒí™œêµ¬ë…íŒ© ì™„ë£Œ (ê°€ê²©: ì›” 13,900ì›)\n",
      "   [4] ë””ì¦ˆë‹ˆ+ ìŠ¤íƒ ë‹¤ë“œ ìƒí™œêµ¬ë…íŒ© ì™„ë£Œ (ê°€ê²©: ì›” 9,900ì›)\n",
      "   [5] í‹°ë¹™ í”„ë¦¬ë¯¸ì—„+ë©”ê°€MGCì»¤í”¼ ì™„ë£Œ (ê°€ê²©: ì›” 17,000ì›)\n",
      "   [6]  í‹°ë¹™ ìŠ¤íƒ ë‹¤ë“œ+ë©”ê°€MGCì»¤í”¼ ì™„ë£Œ (ê°€ê²©: ì›” 13,500ì›)\n",
      "   [7] í‹°ë¹™ ë² ì´ì§+ë©”ê°€MGCì»¤í”¼ ì™„ë£Œ (ê°€ê²©: ì›” 9,500ì›)\n",
      "   [8] í‹°ë¹™ ê´‘ê³ í˜• ìŠ¤íƒ ë‹¤ë“œ+ë©”ê°€MGCì»¤í”¼ ì™„ë£Œ (ê°€ê²©: ì›” 5,500ì›)\n",
      "   [9] ë”¥ì—˜ ì¸ë””ë¹„ì£¼ì–¼ ì™„ë£Œ (ê°€ê²©: ì›” 9,900ì›)\n",
      "   [10] ìœ íŠœë¸Œ í”„ë¦¬ë¯¸ì—„ ìƒí™œêµ¬ë…íŒ© ì™„ë£Œ (ê°€ê²©: ì›” 14,900ì›)\n",
      "   [11] ëª¨ì•„ì§„(êµ­ë‚´í•´ì™¸ë§¤ê±°ì§„ë¬´ì œí•œ) ì™„ë£Œ (ê°€ê²©: ì›” 13,000ì›)\n",
      "   [12] ëª¨ì•„ì§„(êµ­ë‚´ë§¤ê±°ì§„ë¬´ì œí•œ) ì™„ë£Œ (ê°€ê²©: ì›” 7,000ì›)\n",
      "   [13] ëª¨ì•„ì§„(ë§¤ê±°ì§„5ì¢…) ì™„ë£Œ (ê°€ê²©: ì›” 4,000ì›)\n",
      "   [14] ì½´ë‹¤ í”„ë¦¬ë¯¸ì—„ ì™„ë£Œ (ê°€ê²©: ì›” 16,500ì›)\n",
      "   [15] ì½´ë‹¤ í”„ë¦¬ë¯¸ì—„ Lite ì™„ë£Œ (ê°€ê²©: ì›” 9,000ì›)\n",
      "   [16] ìœ íŠœë¸Œ í”„ë¦¬ë¯¸ì—„+ë¡¯ë°ì‹œë„¤ë§ˆ ì™„ë£Œ (ê°€ê²©: ì›” 27,900ì›)\n",
      "   [17] í‹°ë¹™ í”„ë¦¬ë¯¸ì—„+ìŠ¤íƒ€ë²…ìŠ¤ ì™„ë£Œ (ê°€ê²©: ì›” 17,000ì›)\n",
      "   [18] í‹°ë¹™ ìŠ¤íƒ ë‹¤ë“œ+ìŠ¤íƒ€ë²…ìŠ¤ ì™„ë£Œ (ê°€ê²©: ì›” 13,500ì›)\n",
      "   [19] í‹°ë¹™ ë² ì´ì§+ìŠ¤íƒ€ë²…ìŠ¤ ì™„ë£Œ (ê°€ê²©: ì›” 9,500ì›)\n",
      "   [20] ìœ íŠœë¸Œ í”„ë¦¬ë¯¸ì—„+ìŠ¤íƒ€ë²…ìŠ¤ ì™„ë£Œ (ê°€ê²©: ì›” 14,900ì›)\n",
      "   [21] ë””ì¦ˆë‹ˆí”ŒëŸ¬ìŠ¤ í”„ë¦¬ë¯¸ì—„+ìŠ¤íƒ€ë²…ìŠ¤ ì™„ë£Œ (ê°€ê²©: ì›” 13,900ì›)\n",
      "   [22] ë””ì¦ˆë‹ˆí”ŒëŸ¬ìŠ¤ ìŠ¤íƒ ë‹¤ë“œ+ìŠ¤íƒ€ë²…ìŠ¤ ì™„ë£Œ (ê°€ê²©: ì›” 9,900ì›)\n",
      "   [23] TVING í”„ë¦¬ë¯¸ì—„ ì™„ë£Œ (ê°€ê²©: ì›” 16,000ì›)\n",
      "   [24] TVING ìŠ¤íƒ ë‹¤ë“œ ì™„ë£Œ (ê°€ê²©: ì›” 12,500ì›)\n",
      "   [25] TVING ë² ì´ì§ ì™„ë£Œ (ê°€ê²©: ì›” 8,500ì›)\n",
      "   [26] TVING ê´‘ê³ í˜• ìŠ¤íƒ ë‹¤ë“œ ì™„ë£Œ (ê°€ê²©: ì›” 5,000ì›)\n",
      "   [27] ìœ íŠœë¸Œ í”„ë¦¬ë¯¸ì—„ ì™„ë£Œ (ê°€ê²©: ì›” 13,900ì›)\n",
      "âŒ í¬ë¡¤ë§ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜: 'aria-label'\n",
      "\n",
      "âœ… [Step 1] ë°ì´í„° ìˆ˜ì§‘ ë° JSON ì €ì¥ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "def crawl_kt_hybrid():\n",
    "    # 1. Selenium ì„¤ì • (ëª©ë¡ í˜ì´ì§€ìš©)\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "    chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\")\n",
    "    \n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "    \n",
    "    results = []\n",
    "\n",
    "    try:\n",
    "        # 2. ë©”ì¸ ëª©ë¡ í˜ì´ì§€ ì ‘ì† (Selenium)\n",
    "        main_url = \"https://m.my.kt.com/product/s_OttSubscribeView.do\"\n",
    "        print(f\"ë©”ì¸ í˜ì´ì§€ ì ‘ì†({main_url})\")\n",
    "        driver.get(main_url)\n",
    "        time.sleep(5) # ë°ì´í„° ë¡œë”© ëŒ€ê¸°\n",
    "\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        product_list = soup.select(\"ul.opage-subscription li[data-wdiclinkmobileurl]\")\n",
    "        \n",
    "        print(f\"ì´ {len(product_list)}ê°œì˜ ìƒí’ˆ\")\n",
    "\n",
    "        # 3. ê° ìƒí’ˆë³„ ì •ë³´ ì¶”ì¶œ ë° ìƒì„¸ í¬ë¡¤ë§\n",
    "        for i, li in enumerate(product_list):\n",
    "            item = {}\n",
    "            \n",
    "            # [A] ê¸°ë³¸ ì •ë³´ (Graph DBìš©)\n",
    "            item['name'] = li.get('data-ottprodnm')\n",
    "            item['detail_url'] = li.get('data-wdiclinkmobileurl')\n",
    "            \n",
    "            # ê°€ê²© ì¶”ì¶œ (í• ì¸ê°€ ìš°ì„ )\n",
    "            sale_tag = li.select_one(\".discount-price\")\n",
    "            orig_tag = li.select_one(\".price\")\n",
    "            \n",
    "            # aria-label ê°’ ê°€ì ¸ì˜¤ê¸° (ì˜ˆ: \"ì›” 13,900ì›\")\n",
    "            item['price_sale'] = sale_tag['aria-label'] if sale_tag else \"ì •ë³´ì—†ìŒ\"\n",
    "            item['price_original'] = orig_tag['aria-label'] if orig_tag else \"ì •ë³´ì—†ìŒ\"\n",
    "            \n",
    "            # [B] ìƒì„¸ ì•½ê´€ í¬ë¡¤ë§ (Vector DBìš©) - ì†ë„ë¥¼ ìœ„í•´ Requests ì‚¬ìš©\n",
    "            if item['detail_url']:\n",
    "                try:\n",
    "                    # ìƒì„¸ í˜ì´ì§€ëŠ” ë³´í†µ ì •ì  í˜ì´ì§€ë¼ Requestsê°€ ë¹ ë¦„\n",
    "                    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "                    resp = requests.get(item['detail_url'], headers=headers)\n",
    "                    sub_soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "                    \n",
    "                    target_div = sub_soup.find(\"div\", class_=\"pduct-ott\")\n",
    "                    if target_div:\n",
    "                        # <br> -> ê³µë°± ë³€í™˜\n",
    "                        for br in target_div.find_all(\"br\"): br.replace_with(\" \")\n",
    "                        # í…ìŠ¤íŠ¸ ì¶”ì¶œ\n",
    "                        item['terms_text'] = target_div.get_text(separator=\"\\n\", strip=True)\n",
    "                    else:\n",
    "                        item['terms_text'] = \"ìƒì„¸ ì•½ê´€ ì—†ìŒ\"\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"   âŒ ìƒì„¸ ìˆ˜ì§‘ ì‹¤íŒ¨ ({item['name']}): {e}\")\n",
    "                    item['terms_text'] = \"\"\n",
    "            \n",
    "            print(f\"   [{i+1}] {item['name']} ì™„ë£Œ (ê°€ê²©: {item['price_sale']})\")\n",
    "            results.append(item)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ í¬ë¡¤ë§ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜: {e}\")\n",
    "        \n",
    "    finally:\n",
    "        driver.quit()\n",
    "        \n",
    "    return results\n",
    "\n",
    "# === ì‹¤í–‰ ë° ì €ì¥ ===\n",
    "data = crawl_kt_hybrid()\n",
    "\n",
    "# JSON ì €ì¥\n",
    "with open(\"kt_products_hybrid.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"\\nâœ… [Step 1] ë°ì´í„° ìˆ˜ì§‘ ë° JSON ì €ì¥ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "830b16eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš™ï¸ ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶• ì‹œì‘...\n",
      "âœ… Graph DB êµ¬ì¶• ì™„ë£Œ (ë…¸ë“œ 44ê°œ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lg\\AppData\\Local\\Temp\\ipykernel_20848\\754429375.py:49: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Vector DB êµ¬ì¶• ì™„ë£Œ (ë¬¸ì„œ ì²­í¬ 204ê°œ)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import networkx as nx\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "print(\"âš™ï¸ ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶• ì‹œì‘...\")\n",
    "\n",
    "# 1. JSON ë¡œë“œ\n",
    "with open(\"kt_products_hybrid.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    products_data = json.load(f)\n",
    "\n",
    "# === [A] Graph DB êµ¬ì¶• (ìƒí’ˆ -[COSTS]-> ê°€ê²©) ===\n",
    "G = nx.DiGraph()\n",
    "\n",
    "for prod in products_data:\n",
    "    p_name = prod['name']\n",
    "    p_price = prod['price_sale']\n",
    "    \n",
    "    # ë…¸ë“œ ì¶”ê°€\n",
    "    G.add_node(p_name, type=\"product\")\n",
    "    G.add_node(p_price, type=\"price\")\n",
    "    \n",
    "    # ì—£ì§€(ê´€ê³„) ì¶”ê°€\n",
    "    G.add_edge(p_name, p_price, relation=\"COSTS\")\n",
    "    \n",
    "    # (ì‹¬í™”) í• ì¸ê°€ê²©ê³¼ ì›ê°€ ê´€ê³„ë„ ì¶”ê°€ ê°€ëŠ¥\n",
    "    # if prod['price_original'] != \"ì •ë³´ì—†ìŒ\":\n",
    "    #     G.add_edge(p_name, prod['price_original'], relation=\"ORIGINAL_PRICE\")\n",
    "\n",
    "print(f\"âœ… Graph DB êµ¬ì¶• ì™„ë£Œ (ë…¸ë“œ {G.number_of_nodes()}ê°œ)\")\n",
    "\n",
    "\n",
    "# === [B] Vector DB êµ¬ì¶• (ìƒì„¸ ì•½ê´€) ===\n",
    "text_docs = []\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "\n",
    "for prod in products_data:\n",
    "    if prod['terms_text']:\n",
    "        # ì•½ê´€ í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ìë¦„\n",
    "        chunks = splitter.create_documents(\n",
    "            texts=[prod['terms_text']], \n",
    "            metadatas=[{\"product_name\": prod['name']}] # ë©”íƒ€ë°ì´í„°ì— ìƒí’ˆëª… ì‹¬ê¸°\n",
    "        )\n",
    "        text_docs.extend(chunks)\n",
    "\n",
    "# ì„ë² ë”© ë° ì €ì¥\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "vector_db = Chroma.from_documents(text_docs, embeddings)\n",
    "\n",
    "print(f\"âœ… Vector DB êµ¬ì¶• ì™„ë£Œ (ë¬¸ì„œ ì²­í¬ {len(text_docs)}ê°œ)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00e4a568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ’¬ ì§ˆë¬¸: ë””ì¦ˆë‹ˆí”ŒëŸ¬ìŠ¤ í”„ë¦¬ë¯¸ì—„+ë©”ê°€MGCì»¤í”¼ ê°€ê²©ì´ ì–¼ë§ˆì•¼?\n",
      "ğŸ¤– [AIê°€ ì°¸ê³ í•œ ì •ë³´]\n",
      "[ê°€ê²©ì •ë³´] 'ë””ì¦ˆë‹ˆí”ŒëŸ¬ìŠ¤ í”„ë¦¬ë¯¸ì—„+ë©”ê°€MGCì»¤í”¼'ì˜ êµ¬ë…ë£ŒëŠ” ì›” 13,900ì› ì…ë‹ˆë‹¤.\n",
      "[ì•½ê´€-'í‹°ë¹™ í”„ë¦¬ë¯¸ì—„+ë©”ê°€MGCì»¤í”¼'] ì•„ë©”ë¦¬ì¹´ë…¸(HOT) ìƒí’ˆì´ ì œê³µë˜ë©°, ì œê³µëœ ê¸°í”„í‹°ì‡¼ëŠ” ìœ íš¨ê¸°ê°„ ë‚´ ì´ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤. (ìœ íš¨ê¸°ê°„ 30ì¼)\n",
      "ë¶€ê°€ì„œë¹„ìŠ¤ ê²°ì œ/ì·¨ì†Œ/í™˜ë¶ˆ ê´€ë ¨í•´ì„œëŠ” ì•„ë˜ì˜ ì •ì±…ì´ ì ìš©ë©ë‹ˆë‹¤.\n",
      "1) ë¶€ê°€ì„œë¹„ìŠ¤ ê°€ì… í›„, ë§¤ì›” ì„œë¹„ìŠ¤ ì´ìš©ë£Œ ê²°ì œì¼(ì„œë¹„ìŠ¤ ì´ìš©ê¸°ê°„ ì‹œì‘ì¼) ê¸°ì¤€ 7ì¼ ì´ë‚´ í•´ì§€í•˜ì‹œëŠ” ê²½ìš°ì—ëŠ”, í‹°ë¹™ ì½˜í…ì¸ ì™€ ë©”ê°€MGCì»¤í”¼ ê¸°í”„í‹°ì‡¼ ì´ìš© ì—¬ë¶€ì— ë”°ë¼ í•´ì§€ ì²˜ë¦¬ë©ë‹ˆë‹¤....\n",
      "[ì•½ê´€-'í‹°ë¹™ ê´‘ê³ í˜• ìŠ¤íƒ ë‹¤ë“œ+ë©”ê°€MGCì»¤í”¼'] ì•„ë©”ë¦¬ì¹´ë…¸(HOT) ìƒí’ˆì´ ì œê³µë˜ë©°, ì œê³µëœ ê¸°í”„í‹°ì‡¼ëŠ” ìœ íš¨ê¸°ê°„ ë‚´ ì´ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤. (ìœ íš¨ê¸°ê°„ 30ì¼)\n",
      "ë¶€ê°€ì„œë¹„ìŠ¤ ê²°ì œ/ì·¨ì†Œ/í™˜ë¶ˆ ê´€ë ¨í•´ì„œëŠ” ì•„ë˜ì˜ ì •ì±…ì´ ì ìš©ë©ë‹ˆë‹¤.\n",
      "1) ë¶€ê°€ì„œë¹„ìŠ¤ ê°€ì… í›„, ë§¤ì›” ì„œë¹„ìŠ¤ ì´ìš©ë£Œ ê²°ì œì¼(ì„œë¹„ìŠ¤ ì´ìš©ê¸°ê°„ ì‹œì‘ì¼) ê¸°ì¤€ 7ì¼ ì´ë‚´ í•´ì§€í•˜ì‹œëŠ” ê²½ìš°ì—ëŠ”, í‹°ë¹™ ì½˜í…ì¸ ì™€ ë©”ê°€MGCì»¤í”¼ ê¸°í”„í‹°ì‡¼ ì´ìš© ì—¬ë¶€ì— ë”°ë¼ í•´ì§€ ì²˜ë¦¬ë©ë‹ˆë‹¤....\n",
      "--------------------------------------------------\n",
      "ğŸ’¡ (ì´ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ LLMì´ ìì—°ìŠ¤ëŸ½ê²Œ ë‹µë³€í•˜ê²Œ ë©ë‹ˆë‹¤)\n",
      "\n",
      "ğŸ’¬ ì§ˆë¬¸: ë””ì¦ˆë‹ˆí”ŒëŸ¬ìŠ¤ í•´ì§€í•˜ë©´ ìœ„ì•½ê¸ˆ ìˆì–´?\n",
      "ğŸ¤– [AIê°€ ì°¸ê³ í•œ ì •ë³´]\n",
      "[ì•½ê´€-'ë””ì¦ˆë‹ˆ+ í”„ë¦¬ë¯¸ì—„ ìƒí™œêµ¬ë…íŒ©'] ì´ë¯¸ ë””ì¦ˆë‹ˆ+ë¥¼ ì§ì ‘ ê²°ì œ ì¤‘ì¸ ê²½ìš°, ì´ìš© ì¤‘ì¸ ë””ì¦ˆë‹ˆ+ ì´ë©”ì¼ ê³„ì •ì„ ë“±ë¡í•´ì•¼ ì´ì¤‘ ê³¼ê¸ˆ ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë‹¨, ì¸ì•± ê²°ì œ(êµ¬ê¸€ ë° ì• í”Œ)ë¡œ ì´ìš© ì¤‘ì¸ ê²½ìš° ì¸ì•± ê²°ì œ ì‚¬ì—…ìì˜ ê³ ê°ì„¼í„°ë¥¼ í†µí•´ ì¡°ì¹˜(í•´ì§€, í™˜ë¶ˆì‹ ì²­ ë“±) í•˜ì…”ì•¼ í•©ë‹ˆë‹¤....\n",
      "[ì•½ê´€-'ë””ì¦ˆë‹ˆ+ ìŠ¤íƒ ë‹¤ë“œ ìƒí™œêµ¬ë…íŒ©'] ì´ë¯¸ ë””ì¦ˆë‹ˆ+ë¥¼ ì§ì ‘ ê²°ì œ ì¤‘ì¸ ê²½ìš°, ì´ìš© ì¤‘ì¸ ë””ì¦ˆë‹ˆ+ ì´ë©”ì¼ ê³„ì •ì„ ë“±ë¡í•´ì•¼ ì´ì¤‘ ê³¼ê¸ˆ ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë‹¨, ì¸ì•± ê²°ì œ(êµ¬ê¸€ ë° ì• í”Œ)ë¡œ ì´ìš© ì¤‘ì¸ ê²½ìš° ì¸ì•± ê²°ì œ ì‚¬ì—…ìì˜ ê³ ê°ì„¼í„°ë¥¼ í†µí•´ ì¡°ì¹˜(í•´ì§€, í™˜ë¶ˆì‹ ì²­ ë“±) í•˜ì…”ì•¼ í•©ë‹ˆë‹¤....\n",
      "--------------------------------------------------\n",
      "ğŸ’¡ (ì´ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ LLMì´ ìì—°ìŠ¤ëŸ½ê²Œ ë‹µë³€í•˜ê²Œ ë©ë‹ˆë‹¤)\n"
     ]
    }
   ],
   "source": [
    "def ask_hybrid_bot(query):\n",
    "    print(f\"\\nğŸ’¬ ì§ˆë¬¸: {query}\")\n",
    "    print(\"Thinking...\", end=\"\", flush=True)\n",
    "    \n",
    "    context_result = []\n",
    "    \n",
    "    # 1. [Graph Search] ê°€ê²©, ì–¼ë§ˆ, ë¹„ìš© ê´€ë ¨ ì§ˆë¬¸\n",
    "    price_keywords = [\"ì–¼ë§ˆ\", \"ê°€ê²©\", \"ë¹„ìš©\", \"ìš”ê¸ˆ\", \"ì‹¸ê²Œ\"]\n",
    "    if any(k in query for k in price_keywords):\n",
    "        # ê·¸ë˜í”„ì—ì„œ ìƒí’ˆëª…ê³¼ ê°€ê²© ê´€ê³„ë¥¼ íƒìƒ‰\n",
    "        found_in_graph = False\n",
    "        for node in G.nodes():\n",
    "            # ì§ˆë¬¸ì— ìƒí’ˆëª…ì´ í¬í•¨ë˜ì–´ ìˆë‹¤ë©´\n",
    "            if isinstance(node, str) and node in query:\n",
    "                # ê·¸ ìƒí’ˆì˜ ì´ì›ƒ ë…¸ë“œ(ê°€ê²©)ë¥¼ ì°¾ìŒ\n",
    "                neighbors = G.neighbors(node)\n",
    "                for n in neighbors:\n",
    "                    if G.get_edge_data(node, n)['relation'] == 'COSTS':\n",
    "                        context_result.append(f\"[ê°€ê²©ì •ë³´] '{node}'ì˜ êµ¬ë…ë£ŒëŠ” {n} ì…ë‹ˆë‹¤.\")\n",
    "                        found_in_graph = True\n",
    "        \n",
    "        if not found_in_graph:\n",
    "             # ìƒí’ˆëª…ì„ ëª» ì°¾ì•˜ìœ¼ë©´ ì „ì²´ ê°€ê²© ë¦¬ìŠ¤íŠ¸ë¥¼ ì°¸ê³ ìš©ìœ¼ë¡œ ì¤Œ\n",
    "             pass \n",
    "\n",
    "    # 2. [Vector Search] ì•½ê´€, í•´ì§€, ìœ ì˜ì‚¬í•­ ê´€ë ¨ ì§ˆë¬¸\n",
    "    # (í•­ìƒ ì‹¤í–‰í•˜ê±°ë‚˜, íŠ¹ì • í‚¤ì›Œë“œì—ë§Œ ì‹¤í–‰í•  ìˆ˜ ìˆìŒ)\n",
    "    # ì§ˆë¬¸ê³¼ ìœ ì‚¬í•œ ì•½ê´€ ë‚´ìš© ê²€ìƒ‰\n",
    "    vector_results = vector_db.similarity_search(query, k=2)\n",
    "    for doc in vector_results:\n",
    "        context_result.append(f\"[ì•½ê´€-'{doc.metadata['product_name']}'] {doc.page_content[:200]}...\")\n",
    "\n",
    "    # 3. ë‹µë³€ ìƒì„± (LLMì—ê²Œ ì •ë³´ ì „ë‹¬)\n",
    "    final_context = \"\\n\".join(context_result)\n",
    "    \n",
    "    if not final_context:\n",
    "        print(\"\\rğŸ¤– ë‹µë³€: ì£„ì†¡í•©ë‹ˆë‹¤. ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "\n",
    "    # (ì—¬ê¸°ì„œ LLM í˜¸ì¶œ - ì´ì „ ì½”ë“œ í™œìš©)\n",
    "    # ê°„ë‹¨í•œ ì¶œë ¥ì„ ìœ„í•´ printë¡œ ëŒ€ì²´í•˜ì§€ë§Œ, ì‹¤ì œë¡œëŠ” rag_chain.invoke()ì— final_contextë¥¼ ë„£ìœ¼ë©´ ë©ë‹ˆë‹¤.\n",
    "    print(f\"\\rğŸ¤– [AIê°€ ì°¸ê³ í•œ ì •ë³´]\\n{final_context}\")\n",
    "    print(\"-\" * 50)\n",
    "    print(\"ğŸ’¡ (ì´ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ LLMì´ ìì—°ìŠ¤ëŸ½ê²Œ ë‹µë³€í•˜ê²Œ ë©ë‹ˆë‹¤)\")\n",
    "\n",
    "# === í…ŒìŠ¤íŠ¸ ===\n",
    "ask_hybrid_bot(\"ë””ì¦ˆë‹ˆí”ŒëŸ¬ìŠ¤ í”„ë¦¬ë¯¸ì—„+ë©”ê°€MGCì»¤í”¼ ê°€ê²©ì´ ì–¼ë§ˆì•¼?\")\n",
    "ask_hybrid_bot(\"ë””ì¦ˆë‹ˆí”ŒëŸ¬ìŠ¤ í•´ì§€í•˜ë©´ ìœ„ì•½ê¸ˆ ìˆì–´?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfa4e7ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ’¬ ì§ˆë¬¸: ë””ì¦ˆë‹ˆ í”ŒëŸ¬ìŠ¤ê°€ í¬í•¨ëœ ê±° ê°€ì…í•˜ê³  ì‹¶ìœ¼ë©´ ì–´ë–¤ ê²Œ ìˆì–´?\n",
      "ğŸ¤– [AIê°€ ì°¸ê³ í•œ ì •ë³´]\n",
      "[ì•½ê´€-'ë””ì¦ˆë‹ˆ+ í”„ë¦¬ë¯¸ì—„ ìƒí™œêµ¬ë…íŒ©'] ì´ë¯¸ ë””ì¦ˆë‹ˆ+ë¥¼ ì§ì ‘ ê²°ì œ ì¤‘ì¸ ê²½ìš°, ì´ìš© ì¤‘ì¸ ë””ì¦ˆë‹ˆ+ ì´ë©”ì¼ ê³„ì •ì„ ë“±ë¡í•´ì•¼ ì´ì¤‘ ê³¼ê¸ˆ ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë‹¨, ì¸ì•± ê²°ì œ(êµ¬ê¸€ ë° ì• í”Œ)ë¡œ ì´ìš© ì¤‘ì¸ ê²½ìš° ì¸ì•± ê²°ì œ ì‚¬ì—…ìì˜ ê³ ê°ì„¼í„°ë¥¼ í†µí•´ ì¡°ì¹˜(í•´ì§€, í™˜ë¶ˆì‹ ì²­ ë“±) í•˜ì…”ì•¼ í•©ë‹ˆë‹¤....\n",
      "[ì•½ê´€-'ë””ì¦ˆë‹ˆ+ ìŠ¤íƒ ë‹¤ë“œ ìƒí™œêµ¬ë…íŒ©'] ì´ë¯¸ ë””ì¦ˆë‹ˆ+ë¥¼ ì§ì ‘ ê²°ì œ ì¤‘ì¸ ê²½ìš°, ì´ìš© ì¤‘ì¸ ë””ì¦ˆë‹ˆ+ ì´ë©”ì¼ ê³„ì •ì„ ë“±ë¡í•´ì•¼ ì´ì¤‘ ê³¼ê¸ˆ ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë‹¨, ì¸ì•± ê²°ì œ(êµ¬ê¸€ ë° ì• í”Œ)ë¡œ ì´ìš© ì¤‘ì¸ ê²½ìš° ì¸ì•± ê²°ì œ ì‚¬ì—…ìì˜ ê³ ê°ì„¼í„°ë¥¼ í†µí•´ ì¡°ì¹˜(í•´ì§€, í™˜ë¶ˆì‹ ì²­ ë“±) í•˜ì…”ì•¼ í•©ë‹ˆë‹¤....\n",
      "--------------------------------------------------\n",
      "ğŸ’¡ (ì´ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ LLMì´ ìì—°ìŠ¤ëŸ½ê²Œ ë‹µë³€í•˜ê²Œ ë©ë‹ˆë‹¤)\n"
     ]
    }
   ],
   "source": [
    "ask_hybrid_bot(\"ë””ì¦ˆë‹ˆ í”ŒëŸ¬ìŠ¤ê°€ í¬í•¨ëœ ê±° ê°€ì…í•˜ê³  ì‹¶ìœ¼ë©´ ì–´ë–¤ ê²Œ ìˆì–´?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "548b081a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ’¬ ì§ˆë¬¸: ì½´ë‹¤ í¬í•¨ëœ ìš”ê¸ˆì œ ì „ë¶€ ì•Œë ¤ì¤˜\n",
      "ğŸ¤– [AIê°€ ì°¸ê³ í•œ ì •ë³´]\n",
      "[ì•½ê´€-'ë””ì¦ˆë‹ˆí”ŒëŸ¬ìŠ¤ í”„ë¦¬ë¯¸ì—„+ìŠ¤íƒ€ë²…ìŠ¤'] ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•œ ë’¤ [ë‹¤ìŒ]ì„ ëˆ„ë¥´ì„¸ìš”.\n",
      "â€» ë””ì¦ˆë‹ˆ+ Appì´ ì—†ìœ¼ë©´, 2ë‹¨ê³„ ì´í›„ ë‚˜ì˜¤ëŠ” í™”ë©´ìœ¼ë¡œ í”Œë ˆì´ìŠ¤í† ì–´/ì•±ìŠ¤í† ì–´ì—ì„œ ë‹¤ìš´ë¡œë“œ í•˜ì„¸ìš”.\n",
      "ê³„ì • ì •ìƒ ìƒì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸ í•„ìš”ì‹œ\n",
      "ë””ì¦ˆë‹ˆApp-ê³„ì •ì—ì„œ 'ë””ì¦ˆë‹ˆ+ KT(ì¼€ì´í‹°) ê³„ì •ìœ¼ë¡œ ì´ë™í•´ ë””ì¦ˆë‹ˆ+ ë©¤ë²„ì‹­ì„ ê´€ë¦¬í•˜ì„¸ìš”'ê°€ í‘œê¸°ë˜ë©´ ì •ìƒ ìƒì„±ëœ ê²ƒ ì…ë‹ˆë‹¤.\n",
      "â€» '>' í´ë¦­ ì‹œ 'kt.com-ë§ˆì´'í˜ì´ì§€ë¡œ ...\n",
      "[ì•½ê´€-'ë””ì¦ˆë‹ˆí”ŒëŸ¬ìŠ¤ ìŠ¤íƒ ë‹¤ë“œ+ìŠ¤íƒ€ë²…ìŠ¤'] ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•œ ë’¤ [ë‹¤ìŒ]ì„ ëˆ„ë¥´ì„¸ìš”.\n",
      "â€» ë””ì¦ˆë‹ˆ+ Appì´ ì—†ìœ¼ë©´, 2ë‹¨ê³„ ì´í›„ ë‚˜ì˜¤ëŠ” í™”ë©´ìœ¼ë¡œ í”Œë ˆì´ìŠ¤í† ì–´/ì•±ìŠ¤í† ì–´ì—ì„œ ë‹¤ìš´ë¡œë“œ í•˜ì„¸ìš”.\n",
      "ê³„ì • ì •ìƒ ìƒì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸ í•„ìš”ì‹œ\n",
      "ë””ì¦ˆë‹ˆApp-ê³„ì •ì—ì„œ 'ë””ì¦ˆë‹ˆ+ KT(ì¼€ì´í‹°) ê³„ì •ìœ¼ë¡œ ì´ë™í•´ ë””ì¦ˆë‹ˆ+ ë©¤ë²„ì‹­ì„ ê´€ë¦¬í•˜ì„¸ìš”'ê°€ í‘œê¸°ë˜ë©´ ì •ìƒ ìƒì„±ëœ ê²ƒ ì…ë‹ˆë‹¤.\n",
      "â€» '>' í´ë¦­ ì‹œ 'kt.com-ë§ˆì´'í˜ì´ì§€ë¡œ ...\n",
      "--------------------------------------------------\n",
      "ğŸ’¡ (ì´ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ LLMì´ ìì—°ìŠ¤ëŸ½ê²Œ ë‹µë³€í•˜ê²Œ ë©ë‹ˆë‹¤)\n"
     ]
    }
   ],
   "source": [
    "ask_hybrid_bot(\"ì½´ë‹¤ í¬í•¨ëœ ìš”ê¸ˆì œ ì „ë¶€ ì•Œë ¤ì¤˜\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e06de0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
